{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "{\n",
    " \"cells\": [\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"# AI Resume Screening System - Training Demo\\n\",\n",
    "    \"\\n\",\n",
    "    \"This notebook demonstrates:\\n\",\n",
    "    \"1. Loading synthetic data\\n\",\n",
    "    \"2. Computing features and rankings\\n\",\n",
    "    \"3. Training optional ML models\\n\",\n",
    "    \"4. Evaluating model performance\\n\",\n",
    "    \"5. Analyzing feature importance\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Setup\\n\",\n",
    "    \"import sys\\n\",\n",
    "    \"sys.path.insert(0, '..')\\n\",\n",
    "    \"\\n\",\n",
    "    \"import pandas as pd\\n\",\n",
    "    \"import numpy as np\\n\",\n",
    "    \"import matplotlib.pyplot as plt\\n\",\n",
    "    \"import seaborn as sns\\n\",\n",
    "    \"from pathlib import Path\\n\",\n",
    "    \"import json\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Import our modules\\n\",\n",
    "    \"from src.text_extraction import extract_text_from_pdf\\n\",\n",
    "    \"from src.preprocessing import preprocess_text, extract_entities\\n\",\n",
    "    \"from src.embedding import EmbeddingManager\\n\",\n",
    "    \"from src.ranking import ResumeRanker\\n\",\n",
    "    \"from src.trainer import RankingModelTrainer\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Plotting style\\n\",\n",
    "    \"sns.set_style('whitegrid')\\n\",\n",
    "    \"plt.rcParams['figure.figsize'] = (12, 6)\\n\",\n",
    "    \"\\n\",\n",
    "    \"print(\\\"✅ Setup complete\\\")\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## 1. Load Demo Data\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Load resume data\\n\",\n",
    "    \"data_dir = Path('../data/demo')\\n\",\n",
    "    \"resumes_dir = data_dir / 'resumes'\\n\",\n",
    "    \"jobs_dir = data_dir / 'jobs'\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Load resume texts\\n\",\n",
    "    \"resumes = []\\n\",\n",
    "    \"for resume_file in sorted(resumes_dir.glob('*.txt')):\\n\",\n",
    "    \"    with open(resume_file, 'r') as f:\\n\",\n",
    "    \"        text = f.read()\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    cleaned = preprocess_text(text)\\n\",\n",
    "    \"    entities = extract_entities(cleaned)\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    resumes.append({\\n\",\n",
    "    \"        'filename': resume_file.name,\\n\",\n",
    "    \"        'raw_text': text,\\n\",\n",
    "    \"        'cleaned_text': cleaned,\\n\",\n",
    "    \"        'entities': entities\\n\",\n",
    "    \"    })\\n\",\n",
    "    \"\\n\",\n",
    "    \"print(f\\\"Loaded {len(resumes)} resumes\\\")\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Load job descriptions\\n\",\n",
    "    \"jobs = []\\n\",\n",
    "    \"for job_file in sorted(jobs_dir.glob('*.txt')):\\n\",\n",
    "    \"    with open(job_file, 'r') as f:\\n\",\n",
    "    \"        text = f.read()\\n\",\n",
    "    \"    jobs.append({\\n\",\n",
    "    \"        'filename': job_file.name,\\n\",\n",
    "    \"        'text': text\\n\",\n",
    "    \"    })\\n\",\n",
    "    \"\\n\",\n",
    "    \"print(f\\\"Loaded {len(jobs)} job descriptions\\\")\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## 2. Initialize Components\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Initialize embedding manager and ranker\\n\",\n",
    "    \"embedding_manager = EmbeddingManager(cache_dir='../cache/embeddings')\\n\",\n",
    "    \"ranker = ResumeRanker(\\n\",\n",
    "    \"    weight_keyword=0.3,\\n\",\n",
    "    \"    weight_semantic=0.4,\\n\",\n",
    "    \"    weight_experience=0.2,\\n\",\n",
    "    \"    weight_skills=0.1\\n\",\n",
    "    \")\\n\",\n",
    "    \"\\n\",\n",
    "    \"print(\\\"✅ Components initialized\\\")\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## 3. Rank Resumes Against Each Job\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Rank resumes for each job\\n\",\n",
    "    \"all_results = []\\n\",\n",
    "    \"\\n\",\n",
    "    \"for job in jobs:\\n\",\n",
    "    \"    print(f\\\"\\\\nRanking for: {job['filename']}\\\")\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    results = ranker.rank_candidates(\\n\",\n",
    "    \"        resumes=resumes,\\n\",\n",
    "    \"        job_description=job['text'],\\n\",\n",
    "    \"        embedding_manager=embedding_manager\\n\",\n",
    "    \"    )\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    # Add job info to results\\n\",\n",
    "    \"    for r in results:\\n\",\n",
    "    \"        r['job'] = job['filename']\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    all_results.extend(results)\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    # Show top 3\\n\",\n",
    "    \"    print(f\\\"Top 3 candidates:\\\")\\n\",\n",
    "    \"    for i, candidate in enumerate(results[:3], 1):\\n\",\n",
    "    \"        print(f\\\"  {i}. {candidate['filename']}: {candidate['total_score']:.3f}\\\")\\n\",\n",
    "    \"\\n\",\n",
    "    \"print(f\\\"\\\\n✅ Total rankings: {len(all_results)}\\\")\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## 4. Analyze Score Distribution\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Convert to DataFrame for analysis\\n\",\n",
    "    \"df = pd.DataFrame(all_results)\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Score distribution\\n\",\n",
    "    \"fig, axes = plt.subplots(2, 2, figsize=(14, 10))\\n\",\n",
    "    \"\\n\",\n",
    "    \"axes[0, 0].hist(df['keyword_score'], bins=20, alpha=0.7, color='blue')\\n\",\n",
    "    \"axes[0, 0].set_title('Keyword Score Distribution')\\n\",\n",
    "    \"axes[0, 0].set_xlabel('Score')\\n\",\n",
    "    \"axes[0, 0].set_ylabel('Frequency')\\n\",\n",
    "    \"\\n\",\n",
    "    \"axes[0, 1].hist(df['semantic_score'], bins=20, alpha=0.7, color='green')\\n\",\n",
    "    \"axes[0, 1].set_title('Semantic Score Distribution')\\n\",\n",
    "    \"axes[0, 1].set_xlabel('Score')\\n\",\n",
    "    \"\\n\",\n",
    "    \"axes[1, 0].hist(df['experience_score'], bins=20, alpha=0.7, color='orange')\\n\",\n",
    "    \"axes[1, 0].set_title('Experience Score Distribution')\\n\",\n",
    "    \"axes[1, 0].set_xlabel('Score')\\n\",\n",
    "    \"axes[1, 0].set_ylabel('Frequency')\\n\",\n",
    "    \"\\n\",\n",
    "    \"axes[1, 1].hist(df['total_score'], bins=20, alpha=0.7, color='red')\\n\",\n",
    "    \"axes[1, 1].set_title('Total Score Distribution')\\n\",\n",
    "    \"axes[1, 1].set_xlabel('Score')\\n\",\n",
    "    \"\\n\",\n",
    "    \"plt.tight_layout()\\n\",\n",
    "    \"plt.show()\\n\",\n",
    "    \"\\n\",\n",
    "    \"print(\\\"\\\\nScore Statistics:\\\")\\n\",\n",
    "    \"print(df[['keyword_score', 'semantic_score', 'experience_score', 'skills_score', 'total_score']].describe())\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## 5. Score Correlations\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Correlation matrix\\n\",\n",
    "    \"score_cols = ['keyword_score', 'semantic_score', 'experience_score', 'skills_score', 'total_score']\\n\",\n",
    "    \"corr_matrix = df[score_cols].corr()\\n\",\n",
    "    \"\\n\",\n",
    "    \"plt.figure(figsize=(10, 8))\\n\",\n",
    "    \"sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', center=0, \\n\",\n",
    "    \"            square=True, linewidths=1, cbar_kws={\\\"shrink\\\": 0.8})\\n\",\n",
    "    \"plt.title('Score Correlation Matrix')\\n\",\n",
    "    \"plt.tight_layout()\\n\",\n",
    "    \"plt.show()\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## 6. Train Classification Model\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Prepare training data\\n\",\n",
    "    \"trainer = RankingModelTrainer(model_dir='../models')\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Use threshold to create binary labels\\n\",\n",
    "    \"threshold = 0.6\\n\",\n",
    "    \"X, y = trainer.prepare_training_data(all_results, threshold=threshold)\\n\",\n",
    "    \"\\n\",\n",
    "    \"print(f\\\"Training data shape: X={X.shape}, y={y.shape}\\\")\\n\",\n",
    "    \"print(f\\\"Positive class: {np.sum(y)} ({np.mean(y):.1%})\\\")\\n\",\n",
    "    \"print(f\\\"Negative class: {len(y) - np.sum(y)} ({1-np.mean(y):.1%})\\\")\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Train Logistic Regression\\n\",\n",
    "    \"lr_results = trainer.train_logistic_regression(X, y)\\n\",\n",
    "    \"\\n\",\n",
    "    \"print(\\\"\\\\n=== Logistic Regression Results ===\\\")\\n\",\n",
    "    \"print(f\\\"Train Accuracy: {lr_results['train_accuracy']:.3f}\\\")\\n\",\n",
    "    \"print(f\\\"Test Accuracy: {lr_results['test_accuracy']:.3f}\\\")\\n\",\n",
    "    \"print(f\\\"CV Mean: {lr_results['cv_mean']:.3f} (+/- {lr_results['cv_std']:.3f})\\\")\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Save model\\n\",\n",
    "    \"trainer.save_model('logistic_regression_model.pkl')\\n\",\n",
    "    \"print(\\\"\\\\n✅ Model saved\\\")\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Train Random Forest\\n\",\n",
    "    \"rf_results = trainer.train_random_forest(X, y)\\n\",\n",
    "    \"\\n\",\n",
    "    \"print(\\\"\\\\n=== Random Forest Results ===\\\")\\n\",\n",
    "    \"print(f\\\"Train Accuracy: {rf_results['train_accuracy']:.3f}\\\")\\n\",\n",
    "    \"print(f\\\"Test Accuracy: {rf_results['test_accuracy']:.3f}\\\")\\n\",\n",
    "    \"\\n\",\n",
    "    \"print(\\\"\\\\nFeature Importance:\\\")\\n\",\n",
    "    \"for feature, importance in rf_results['feature_importance'].items():\\n\",\n",
    "    \"    print(f\\\"  {feature}: {importance:.3f}\\\")\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Visualize feature importance\\n\",\n",
    "    \"features = list(rf_results['feature_importance'].keys())\\n\",\n",
    "    \"importances = list(rf_results['feature_importance'].values())\\n\",\n",
    "    \"\\n\",\n",
    "    \"plt.figure(figsize=(10, 6))\\n\",\n",
    "    \"plt.bar(features, importances, color='skyblue')\\n\",\n",
    "    \"plt.title('Random Forest Feature Importance')\\n\",\n",
    "    \"plt.xlabel('Feature')\\n\",\n",
    "    \"plt.ylabel('Importance')\\n\",\n",
    "    \"plt.xticks(rotation=45)\\n\",\n",
    "    \"plt.tight_layout()\\n\",\n",
    "    \"plt.show()\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Train XGBoost\\n\",\n",
    "    \"xgb_results = trainer.train_xgboost(X, y)\\n\",\n",
    "    \"\\n\",\n",
    "    \"print(\\\"\\\\n=== XGBoost Results ===\\\")\\n\",\n",
    "    \"print(f\\\"Train Accuracy: {xgb_results['train_accuracy']:.3f}\\\")\\n\",\n",
    "    \"print(f\\\"Test Accuracy: {xgb_results['test_accuracy']:.3f}\\\")\\n\",\n",
    "    \"\\n\",\n",
    "    \"print(\\\"\\\\nFeature Importance:\\\")\\n\",\n",
    "    \"for feature, importance in xgb_results['feature_importance'].items():\\n\",\n",
    "    \"    print(f\\\"  {feature}: {importance:.3f}\\\")\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## 7. Model Comparison\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Compare models\\n\",\n",
    "    \"models = ['Logistic Regression', 'Random Forest', 'XGBoost']\\n\",\n",
    "    \"train_scores = [\\n\",\n",
    "    \"    lr_results['train_accuracy'],\\n\",\n",
    "    \"    rf_results['train_accuracy'],\\n\",\n",
    "    \"    xgb_results['train_accuracy']\\n\",\n",
    "    \"]\\n\",\n",
    "    \"test_scores = [\\n\",\n",
    "    \"    lr_results['test_accuracy'],\\n\",\n",
    "    \"    rf_results['test_accuracy'],\\n\",\n",
    "    \"    xgb_results['test_accuracy']\\n\",\n",
    "    \"]\\n\",\n",
    "    \"\\n\",\n",
    "    \"x = np.arange(len(models))\\n\",\n",
    "    \"width = 0.35\\n\",\n",
    "    \"\\n\",\n",
    "    \"fig, ax = plt.subplots(figsize=(10, 6))\\n\",\n",
    "    \"ax.bar(x - width/2, train_scores, width, label='Train', color='lightblue')\\n\",\n",
    "    \"ax.bar(x + width/2, test_scores, width, label='Test', color='lightcoral')\\n\",\n",
    "    \"\\n\",\n",
    "    \"ax.set_ylabel('Accuracy')\\n\",\n",
    "    \"ax.set_title('Model Comparison')\\n\",\n",
    "    \"ax.set_xticks(x)\\n\",\n",
    "    \"ax.set_xticklabels(models)\\n\",\n",
    "    \"ax.legend()\\n\",\n",
    "    \"ax.set_ylim([0, 1.1])\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Add value labels\\n\",\n",
    "    \"for i, (train, test) in enumerate(zip(train_scores, test_scores)):\\n\",\n",
    "    \"    ax.text(i - width/2, train + 0.02, f'{train:.3f}', ha='center', va='bottom')\\n\",\n",
    "    \"    ax.text(i + width/2, test + 0.02, f'{test:.3f}', ha='center', va='bottom')\\n\",\n",
    "    \"\\n\",\n",
    "    \"plt.tight_layout()\\n\",\n",
    "    \"plt.show()\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## 8. Top Candidates Analysis\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Find top candidates for each job\\n\",\n",
    "    \"for job in jobs:\\n\",\n",
    "    \"    job_results = [r for r in all_results if r['job'] == job['filename']]\\n\",\n",
    "    \"    job_results_sorted = sorted(job_results, key=lambda x: x['total_score'], reverse=True)\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    print(f\\\"\\\\n{'='*60}\\\")\\n\",\n",
    "    \"    print(f\\\"Job: {job['filename']}\\\")\\n\",\n",
    "    \"    print(f\\\"{'='*60}\\\")\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    for i, candidate in enumerate(job_results_sorted[:5], 1):\\n\",\n",
    "    \"        print(f\\\"\\\\n#{i} - {candidate['filename']}\\\")\\n\",\n",
    "    \"        print(f\\\"  Overall Score: {candidate['total_score']:.3f}\\\")\\n\",\n",
    "    \"        print(f\\\"  Breakdown:\\\")\\n\",\n",
    "    \"        print(f\\\"    - Keyword:   {candidate['keyword_score']:.3f}\\\")\\n\",\n",
    "    \"        print(f\\\"    - Semantic:  {candidate['semantic_score']:.3f}\\\")\\n\",\n",
    "    \"        print(f\\\"    - Experience: {candidate['experience_score']:.3f}\\\")\\n\",\n",
    "    \"        print(f\\\"    - Skills:    {candidate['skills_score']:.3f}\\\")\\n\",\n",
    "    \"        print(f\\\"  Summary: {candidate['explanation']['summary']}\\\")\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## 9. Save Results\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Save results to CSV\\n\",\n",
    "    \"output_file = '../data/demo/ranking_results.csv'\\n\",\n",
    "    \"df_export = df[['filename', 'job', 'total_score', 'keyword_score', \\n\",\n",
    "    \"                'semantic_score', 'experience_score', 'skills_score']].copy()\\n\",\n",
    "    \"df_export.to_csv(output_file, index=False)\\n\",\n",
    "    \"\\n\",\n",
    "    \"print(f\\\"✅ Results saved to {output_file}\\\")\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Save model comparison\\n\",\n",
    "    \"comparison_df = pd.DataFrame({\\n\",\n",
    "    \"    'Model': models,\\n\",\n",
    "    \"    'Train_Accuracy': train_scores,\\n\",\n",
    "    \"    'Test_Accuracy': test_scores\\n\",\n",
    "    \"})\\n\",\n",
    "    \"comparison_df.to_csv('../data/demo/model_comparison.csv', index=False)\\n\",\n",
    "    \"\\n\",\n",
    "    \"print(\\\"✅ Model comparison saved\\\")\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## 10. Conclusion\\n\",\n",
    "    \"\\n\",\n",
    "    \"This notebook demonstrated:\\n\",\n",
    "    \"- Loading and preprocessing resume data\\n\",\n",
    "    \"- Computing multi-component relevance scores\\n\",\n",
    "    \"- Training and comparing ML models\\n\",\n",
    "    \"- Analyzing feature importance\\n\",\n",
    "    \"- Identifying top candidates\\n\",\n",
    "    \"\\n\",\n",
    "    \"### Next Steps:\\n\",\n",
    "    \"1. **Fine-tune weights**: Adjust scoring weights based on your priorities\\n\",\n",
    "    \"2. **Use larger models**: Upgrade to better embedding models for improved accuracy\\n\",\n",
    "    \"3. **Add more features**: Include education level, certifications, etc.\\n\",\n",
    "    \"4. **Deploy API**: Use the FastAPI wrapper for programmatic access\\n\",\n",
    "    \"5. **Integrate with ATS**: Connect to your applicant tracking system\"\n",
    "   ]\n",
    "  }\n",
    " ],\n",
    " \"metadata\": {\n",
    "  \"kernelspec\": {\n",
    "   \"display_name\": \"Python 3\",\n",
    "   \"language\": \"python\",\n",
    "   \"name\": \"python3\"\n",
    "  },\n",
    "  \"language_info\": {\n",
    "   \"codemirror_mode\": {\n",
    "    \"name\": \"ipython\",\n",
    "    \"version\": 3\n",
    "   },\n",
    "   \"file_extension\": \".py\",\n",
    "   \"mimetype\": \"text/x-python\",\n",
    "   \"name\": \"python\",\n",
    "   \"nbconvert_exporter\": \"python\",\n",
    "   \"pygments_lexer\": \"ipython3\",\n",
    "   \"version\": \"3.10.0\"\n",
    "  }\n",
    " },\n",
    " \"nbformat\": 4,\n",
    " \"nbformat_minor\": 4\n",
    "}"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
